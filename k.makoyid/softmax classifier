import torch
import torchvision
import torchvision.transforms as transforms
from torchvision.datasets import ImageFolder
from torchvision.models import resnet34
from google.colab import drive
import matplotlib.pyplot as plt
import numpy as np
import torch.nn as nn
import torch.optim as optim
from PIL import Image

drive.mount('/content/drive')

data_dir = '/content/drive/MyDrive/data'

def convert_to_rgb(image):
    return image.convert('RGB')

transform_train = transforms.Compose([
    transforms.Lambda(convert_to_rgb),
    transforms.Resize((256, 256)),
    transforms.RandomCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

transform_test = transforms.Compose([
    transforms.Lambda(convert_to_rgb),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

batch_size = 32

trainset = ImageFolder(root='/content/drive/My Drive/data/train', transform=transform_train)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                          shuffle=True, num_workers=2)

testset = ImageFolder(root='/content/drive/My Drive/data/test', transform=transform_test)
testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
                                         shuffle=False, num_workers=2)

classes = trainset.classes

model = resnet34(pretrained=True)

for param in model.parameters():
    param.requires_grad = False

num_ftrs = model.fc.in_features
model.fc = nn.Sequential(
    nn.Linear(num_ftrs, 512),
    nn.ReLU(),
    nn.Dropout(0.5),
    nn.Linear(512, 256),
    nn.ReLU(),
    nn.Dropout(0.3),
    nn.Linear(256, len(classes)),
    nn.Softmax(dim=1)
)

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model = model.to(device)

class_weights = torch.tensor([1.0, 2.0, 1.0]).to(device)
criterion = nn.NLLLoss(weight=class_weights)
optimizer = optim.Adam(model.fc.parameters(), lr=0.001)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)

def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        for inputs, labels in trainloader:
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(torch.log(outputs), labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * inputs.size(0)

        epoch_loss = running_loss / len(trainset)

        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for inputs, labels in testloader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        epoch_acc = 100 * correct / total
        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')

        scheduler.step(epoch_acc)

    return model

def imshow(img):
    img = img / 2 + 0.5
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

dataiter = iter(trainloader)
images, labels = next(dataiter)

imshow(torchvision.utils.make_grid(images[:5]))
print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(5)))

model = train_model(model, criterion, optimizer, scheduler, num_epochs=50)

torch.save(model.state_dict(), 'custom_resnet_softmax.pth')

model.eval()
correct = 0
total = 0
class_correct = list(0. for i in range(len(classes)))
class_total = list(0. for i in range(len(classes)))

with torch.no_grad():
    for inputs, labels in testloader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
        c = (predicted == labels).squeeze()
        for i in range(len(labels)):
            label = labels[i]
            class_correct[label] += c[i].item()
            class_total[label] += 1

print(f'Accuracy of the network on the test images: {100 * correct / total:.1f} %')

for i in range(len(classes)):
    print(f'Accuracy of {classes[i]}: {100 * class_correct[i] / class_total[i]:.1f}%')

print(f'Using device: {device}')

-------------------------------------------------------------------------------------------------------------

def get_images_of_different_classes(dataloader, num_images, classes):
    images = []
    labels = []
    class_count = {c: 0 for c in range(len(classes))}

    for data in dataloader:
        inputs, targets = data
        for input, target in zip(inputs, targets):
            if class_count[target.item()] < num_images // len(classes):
                images.append(input)
                labels.append(target)
                class_count[target.item()] += 1

        if sum(class_count.values()) == num_images:
            break

    if not images:
        return None

    return torch.stack(images), torch.tensor(labels)

result = get_images_of_different_classes(testloader, 10, classes)

if result:
    images, labels = result

    plt.figure(figsize=(20, 10))
    imshow(torchvision.utils.make_grid(images, nrow=5))

    print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(len(labels))))

    model.eval()
    with torch.no_grad():
        outputs = model(images.to(device))
        probabilities = torch.nn.functional.softmax(outputs, dim=1).cpu().numpy()
        _, predicted = torch.max(outputs, 1)

    print('Predicted: ')
    for j in range(len(labels)):
        pred_class = classes[predicted[j].item()]
        pred_prob = probabilities[j][predicted[j].item()] * 100
        print(f'{pred_class:5s} with {pred_prob:.2f}% confidence')

        print('  All class probabilities:')
        for i, class_name in enumerate(classes):
            print(f'    {class_name:5s}: {probabilities[j][i]*100:.2f}%')
        print()

    correct = (predicted == labels.to(device)).sum().item()
    print(f'Accuracy for these {len(labels)} images: {100 * correct / len(labels):.1f}%')
else:
    print("No images were found.")

------------------------------------------------------------------------------------------------------------
result: 
GroundTruth:  car   car   car   tank  tank  tank  truck truck truck
Predicted: 
car   with 54.43% confidence
  All class probabilities:
    car  : 54.43%
    tank : 21.82%
    truck: 23.75%

car   with 57.56% confidence
  All class probabilities:
    car  : 57.56%
    tank : 21.21%
    truck: 21.23%

car   with 44.22% confidence
  All class probabilities:
    car  : 44.22%
    tank : 23.08%
    truck: 32.70%

tank  with 56.15% confidence
  All class probabilities:
    car  : 22.15%
    tank : 56.15%
    truck: 21.70%

tank  with 56.08% confidence
  All class probabilities:
    car  : 21.94%
    tank : 56.08%
    truck: 21.98%

tank  with 57.52% confidence
  All class probabilities:
    car  : 21.26%
    tank : 57.52%
    truck: 21.22%

truck with 57.41% confidence
  All class probabilities:
    car  : 21.33%
    tank : 21.26%
    truck: 57.41%

truck with 57.47% confidence
  All class probabilities:
    car  : 21.30%
    tank : 21.23%
    truck: 57.47%

truck with 50.73% confidence
  All class probabilities:
    car  : 26.81%
    tank : 22.46%
    truck: 50.73%

Accuracy for these 9 images: 100.0%
