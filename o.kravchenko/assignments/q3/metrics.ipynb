{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "FOLDERNAME = \"numpy/assignment1\"\n",
    "\n",
    "personal_dir = Path(os.getcwd())\n",
    "sys.path.append(personal_dir)\n",
    "repo_dir = Path(os.getcwd()).parents[2]\n",
    "sys.path.append(Path(repo_dir, FOLDERNAME))\n",
    "\n",
    "# This downloads the CIFAR-10 dataset to your Drive\n",
    "# if it doesn't already exist.\n",
    "%cd $repo_dir/$FOLDERNAME/cs231n/datasets/\n",
    "!bash get_datasets.sh\n",
    "%cd $repo_dir/$FOLDERNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CIFAR10_data(\n",
    "    num_training=49000, num_validation=1000, num_test=1000, num_dev=500\n",
    "):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    SVM, but condensed to a single function.\n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = \"cs231n/datasets/cifar-10-batches-py\"\n",
    "\n",
    "    # Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "    try:\n",
    "        del X_train, y_train\n",
    "        del X_test, y_test\n",
    "        print(\"Clear previously loaded data.\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "\n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "\n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_dev -= mean_image\n",
    "\n",
    "    # add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = (\n",
    "    get_CIFAR10_data()\n",
    ")\n",
    "print(\"Train data shape: \", X_train.shape)\n",
    "print(\"Train labels shape: \", y_train.shape)\n",
    "print(\"Validation data shape: \", X_val.shape)\n",
    "print(\"Validation labels shape: \", y_val.shape)\n",
    "print(\"Test data shape: \", X_test.shape)\n",
    "print(\"Test labels shape: \", y_test.shape)\n",
    "print(\"dev data shape: \", X_dev.shape)\n",
    "print(\"dev labels shape: \", y_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $personal_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding best hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from itertools import product\n",
    "from math import floor\n",
    "\n",
    "from linear_classifier import Softmax\n",
    "from logistic_regression_classifier import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [1e-7, 5e-7]\n",
    "regularization_strengths = [2.5e4, 5e4]\n",
    "epochs = 2\n",
    "batch_size = 200\n",
    "num_iters = floor(X_train.shape[0] * epochs / batch_size)\n",
    "CLASSIFIER_CLASS = Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add time measurement for each epoch\n",
    "\n",
    "# TODO: add augmentation for each epoch\n",
    "\n",
    "# TODO: use sigmoid instead of softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "time_stats = []\n",
    "total_loss_history = []\n",
    "total_weights_history = []\n",
    "hyperparams_comb = list(product(learning_rates, regularization_strengths))\n",
    "\n",
    "for lr, reg in hyperparams_comb:\n",
    "    classifier = CLASSIFIER_CLASS()\n",
    "\n",
    "    start_time = time.time()\n",
    "    loss_history, weights_history = classifier.train(\n",
    "        X_train, y_train, lr, reg, num_iters=num_iters, batch_size=batch_size\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    time_stats.append(end_time - start_time)\n",
    "    total_loss_history.append(loss_history)\n",
    "    total_weights_history.append(weights_history)\n",
    "\n",
    "    y_train_pred = classifier.predict(X_train)\n",
    "    y_val_pred = classifier.predict(X_val)\n",
    "\n",
    "    train_accuracy = np.mean(y_train == y_train_pred)\n",
    "    val_accuracy = np.mean(y_val == y_val_pred)\n",
    "    results[(lr, reg)] = train_accuracy, val_accuracy\n",
    "\n",
    "    if val_accuracy > best_val:\n",
    "        best_val = val_accuracy\n",
    "        best_softmax = classifier\n",
    "\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print(\n",
    "        \"lr %e reg %e train accuracy: %f val accuracy: %f\"\n",
    "        % (lr, reg, train_accuracy, val_accuracy)\n",
    "    )\n",
    "\n",
    "print(\n",
    "    \"best validation accuracy achieved during cross-validation: %f\" % best_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print(\"softmax on raw pixels final test set accuracy: %f\" % (test_accuracy,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process statistics and show metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_acc_history = []\n",
    "total_test_acc_history = []\n",
    "\n",
    "for weights_history in total_weights_history:\n",
    "    train_acc_history = []\n",
    "    test_acc_history = []\n",
    "    for w in weights_history:\n",
    "        classifier = CLASSIFIER_CLASS(w)\n",
    "\n",
    "        y_train_pred = classifier.predict(X_train)\n",
    "        y_test_pred = classifier.predict(X_test)\n",
    "\n",
    "        train_acc = np.mean(y_train == y_train_pred)\n",
    "        test_acc = np.mean(y_test == y_test_pred)\n",
    "\n",
    "        train_acc_history.append(train_acc)\n",
    "        test_acc_history.append(test_acc)\n",
    "    total_train_acc_history.append(train_acc_history)\n",
    "    total_test_acc_history.append(test_acc_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"LR & Reg\": hyperparams_comb,\n",
    "        \"Loss\": total_loss_history,\n",
    "        \"Train accuracy\": total_train_acc_history,\n",
    "        \"Test accuracy\": total_test_acc_history,\n",
    "        \"Index\": [np.arange(len(total_loss_history[0]))]\n",
    "        * len(total_loss_history),\n",
    "    }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = pd.DataFrame()\n",
    "frequency = 10\n",
    "for idx, row in df.iterrows():\n",
    "    train_data = pd.DataFrame(\n",
    "        {\n",
    "            f\"Iterations ({frequency=})\": row[\"Index\"][::frequency],\n",
    "            \"Accuracy\": row[\"Train accuracy\"][::frequency],\n",
    "            \"Dataset Type\": \"Train\",\n",
    "            \"LR & Reg\": str(row[\"LR & Reg\"]),\n",
    "        }\n",
    "    )\n",
    "    test_data = pd.DataFrame(\n",
    "        {\n",
    "            f\"Iterations ({frequency=})\": row[\"Index\"][::frequency],\n",
    "            \"Accuracy\": row[\"Test accuracy\"][::frequency],\n",
    "            \"Dataset Type\": \"Test\",\n",
    "            \"LR & Reg\": str(row[\"LR & Reg\"]),\n",
    "        }\n",
    "    )\n",
    "    transformed_data = pd.concat(\n",
    "        [transformed_data, train_data, test_data], ignore_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: loss vs iters, acc vs iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    transformed_data,\n",
    "    col=\"LR & Reg\",\n",
    "    hue=\"Dataset Type\",\n",
    "    height=5,\n",
    "    aspect=1.5,\n",
    "    col_wrap=2,\n",
    ")\n",
    "g.map(sns.lineplot, f\"Iterations ({frequency=})\", \"Accuracy\").add_legend()\n",
    "g.set_axis_labels(f\"Iterations ({frequency=})\", \"Accuracy\")\n",
    "\n",
    "plt.subplots_adjust(top=0.88, wspace=0.2, hspace=0.2)\n",
    "g.figure.suptitle(\n",
    "    \"Train and Test Accuracy Data for each learning rate and regularization strength\"\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
